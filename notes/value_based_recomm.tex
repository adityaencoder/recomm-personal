\documentclass[11]{article}
\usepackage[utf8]{inputenc}
\usepackage{float}
\usepackage[pdfstartview=FitH, CJKbookmarks=true, bookmarksnumbered=true,
            bookmarksopen=true,
            colorlinks, pdfborder=001, linkcolor=red, anchorcolor=blue, citecolor=blue]{hyperref}
\usepackage{ragged2e, amsmath,  array, amsfonts}
\usepackage{tcolorbox, color}
\usepackage{caption, subcaption, graphicx}
\usepackage{geometry}

\newgeometry{hmargin={1.3in, 1.3in}}   % set the margins
%\newgeometry{vmargin={1mm}, hmargin={12mm,17mm}}   % set the margins



\tcbuselibrary{theorems}

\newtcbtheorem[number within=section]{mytheo}{  }%
{colback=white!5,colframe=red!50!black,fonttitle=\bfseries}{th}

\title{Value-sensitive product (content) recommendation}
\author{Aditya Kiran }
\date{\today}


\input{./ak-preamble.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document} %JSR
\maketitle
\section{Abstract}


\section{Introduction}

\section{Formulation}
For each article $A_i$ in our database we know its 3 properties:
\begin{enumerate}

\item \textbf{$v^1_i$ is a vector of its graph-representation}:

Let $(V^1, E^1)$ be the coviewership graph. Here $V^1$ represents the set of graph-embeddings of all nodes (articles) $v^1$, and $E^1$ represents set of all edges connecting those nodes.  $d^1_{ij}$'s be the distance between $v^1_i$ and $v^1_j$. 
 
\item \textbf{$v^2_i$ is a vector of its sentence embedding}:

Let $(V^2, E^2)$ be the similarity graph. As above, $d^2_{ij}$'s be the distance between $v^2_i$ and $v^2_j$.

\item \textbf{$c_i$ is the value associated with that article}
\end{enumerate}
So, each article $A_i$ is represented by this triad $\{ v^1_i, v^2_i, c_i \}$. Although, this is a very general formulation. For the sake of simplicity, for now we will just assume that each  article is characterized by its sentence embedding and its value.

In this work, we will use Healthline content recommendation as a setting usecase to demonstrate our idea.

\vspace{0.3cm}

\redak{\sdhd{Problem Statement:}}\\
Now, the problem statement is: \\
Given that a user is reading an article $A_i$, what article must be recommended next so that we
\begin{enumerate}
\item maximize the content relevance to the user
\item maximize the ad-monetary value.
\end{enumerate} 

Mathematically, given $A_i$, we seek $A_j$ such that:
\begin{align*}
 j&= \argmax_J   \phi(A_i, A_{J}) ,
\end{align*}
where $\phi$ is the utility function. This above formulation is mainly for our \textit{Read Next} pages, but it could be easily extended to \textit{Infinite scroll}.

\sdhd{\redak{How do we choose the utility function $\phi$?}}

Each article $A_J$ is attributed with its sentence-embedding and its value. So we must design a utility function $\phi$ that maps its attributes to a real value:
\[ \phi: \mathbb{R}^D\times\mathbb{R}^D\times\mathbb{R}\ \to \mathbb{R} \]

\begin{itemize}
\item $\phi$ must be directly proportional to the  value of the article $A_J$ being recommended \[ \phi(A_i, A_{J})  \propto c_J \]
\item $\phi$ must be inversely proportional to the  distance of the article $A_J$ from the current article $A_i$ \[ \phi(A_i, A_{J})  \propto \frac{1}{|d_i-d_J|} =\frac{1}{d_{iJ}} \]
\end{itemize}

Hence, we choose $$\phi(A_p, A_{q}):=\dfrac{(c_{q})^{r_1}}{(d_{pq})^{r_2}}.$$ Here $r_1$ and $r_2$ are the parameters that control the contribution of the value and the distance, on the utility term $\phi$ respectively. \\Note: The special case of $\{r_1=0, r_2=1 \}$ reduces the method back to the BAU. So once implemented, this method is easily backward compatible.
\vspace{0.3cm}

\sdhd{\redak{Assumptions made:}}
\begin{enumerate}
\item The value of an article $\approx$ its $\left(\dfrac{\text{total revenue}}{\text{total impressions}} \right)$  from the past
\item The article value remains almost unchanged for 1 week
\item Each article is characterized by the universal sentence embedding vector of its: 
\begin{itemize}
\item post\_title
\item meta\_title
\item summary
\end{itemize}


\end{enumerate}


\sdhd{\redak{Formulation for Infinite scroll:}} 

Quite often, we recommend more than just one article, either in the form of infinite-scroll or the `\textit{Next Page}' option.

So a more general form of the problem is:
Given an article $A_i$, we seek (N-1) articles $\{A_{a_1}, A_{a_2}, \cdots A_{a_{N-1}}\}$ such that:
\begin{align*}
\{a_1 \cdots a_{N-1}\} &= \argmax_{\{b_1\cdots b_{{N-1}}\}}  \sum_{k=1}^{N-1}  \gamma^{k-1} \phi(A_i, A_{b_k}),
\end{align*}
where $0<\gamma<1$ is called the discount factor.

Finally, after we know the `optimal' recommendations, we evaluate the discounted value as \[\mathcal{V}_{disc}:=\sum_{k=1}^{N-1}  \gamma^{k-1} c_{a_k} \]
We use the discounted-value instead of actual value to account for the fact that the likelihood of a user reading an article decreases with increasing scroll depth.

\section{Results}

\sdhd{\redak{Simulation results for \textit{Infinite scroll}:}}\\
We used $r_1=0.8, r_2=15, \gamma=0.09, N=6,$ and ran 30,000 random simulations.
\begin{itemize}
\item We observe a {\textbf{lift of 14.76\% in the discounted value}}
\[ \left( \dfrac{  \mathcal{V}^{VAL}_{disc}-\mathcal{V}^{BAU}_{disc}  }{\mathcal{V}^{BAU}_{disc} } \right) \times 100  =14.76\% \]
This lift can be interpreted as the revenue lift seen per impression on an average.
\item We observe a {\textbf{reduction in relevance or similarity  of 0.4\%}}

I.e., Mean cosine-similarity between the recommended articles and the article being read:
\begin{itemize}
\item in BAU: 0.709
\item in VAL: 0.706.
\end{itemize}
\end{itemize}

\imcenter{width=1.0\textwidth}{images/example2.png}{Example recommendations showing a lift in the value for the same set of articles.}


\begin{figure}[H]
	\centering
	\begin{subfigure}[t]{0.45\textwidth}
		\centering
		\includegraphics[width=1.1\linewidth]{images/value_abs_recomm.png} 
		\caption{Mean of unweighted-values in the recommended $(N-1)$ articles} \label{im:11}
	\end{subfigure}
	\hfill%\hspace{1.8in}
	\begin{subfigure}[t]{0.45\textwidth}
		\centering
		\includegraphics[width=1.1\linewidth]{images/value_weight_recomm.png}
		\caption{Mean of the discounted-values} \label{im:12}
	\end{subfigure}
	\begin{subfigure}[t]{0.49\textwidth}
		\centering
		\includegraphics[width=1.0\linewidth]{images/cossim_recomm.png}
		\caption{Mean cosine-similarities} \label{im:22}
	\end{subfigure}	
	
	\caption{Conglomerated results of the recommended articles after doing the random simulations.} \label{im:33}
\end{figure}


\imcenter{scale=0.6}{images/distrib_lifts.png}{Distribution of the observed lift in each random simulation.}


\section{Conclusion}
As seen from Fig. (\ref{im:22}), by achieving an almost equal cosine similarity score as the BAU, we are achieving a higher value (Fig. (\ref{im:12})) using the value-based method.

Hence we think that it is worth implementing this value-based recommendation method into a live A/B test with the BAU.

\newpage
\section{Miscellaneous}
\sdhd{\redak{Some questions:}}\\
\begin{enumerate}
\item Any reason why the articles are so differently valued?
\begin{itemize}
\item I.e., why are there different articles which are quite similar to a given current article, but with so much variance in the values? So much so that we see a big value  lift?
\end{itemize}
\item Do we have any idea how seasonality affects the volatility of article value?  Do we have enough confidence on the value being stable over time? 
\begin{itemize}
\item Is there a way we can get the $c$-values within a desired time window, instead of an all time historical value? Yes. But can we also get to plot the values over time? 
\item Can we somehow test these $c$-values to ascertain our attribution of an article to a value? 
\end{itemize}
\item In the process of showing article an A instead of article B, I hope that we aren't just transferring money from one pocket to another?
\item \text{[Do analysis]} It would be good to know how often “high-value” pages are recommended with this approach vs the similarity based approach.


\end{enumerate}


%\begin{itemize}
%\item If something has a diminishing returns behavior, use a (sigmoid) $\frac{K}{1+e^{-bx}}$ or (a sublinear) $Kx^{b}$ with  $0<b<1$
%\item If it has a fast decreasing trend, use (shifted exponential) $a+Ke^{-b(x-c)}$
%\item For Gaussians, use the standard Gaussian PDF
%\item For other simpler forms, some polynomial maybe
%\end{itemize}



\end{document}
